{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29ed280",
   "metadata": {
    "papermill": {
     "duration": 0.003325,
     "end_time": "2025-12-06T08:33:15.425146",
     "exception": false,
     "start_time": "2025-12-06T08:33:15.421821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Local Excitation Network for Restoring a JPEG-Comp**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71289035",
   "metadata": {
    "papermill": {
     "duration": 0.001881,
     "end_time": "2025-12-06T08:33:15.429346",
     "exception": false,
     "start_time": "2025-12-06T08:33:15.427465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1) Environment check / input paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a67ed05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T08:33:15.434654Z",
     "iopub.status.busy": "2025-12-06T08:33:15.434367Z",
     "iopub.status.idle": "2025-12-06T08:33:26.670300Z",
     "shell.execute_reply": "2025-12-06T08:33:26.668854Z"
    },
    "papermill": {
     "duration": 11.240709,
     "end_time": "2025-12-06T08:33:26.671980",
     "exception": false,
     "start_time": "2025-12-06T08:33:15.431271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4f6fa",
   "metadata": {
    "papermill": {
     "duration": 0.002022,
     "end_time": "2025-12-06T08:33:26.676792",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.674770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2) Install / import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa61519e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T08:33:26.682243Z",
     "iopub.status.busy": "2025-12-06T08:33:26.681841Z",
     "iopub.status.idle": "2025-12-06T08:33:26.708878Z",
     "shell.execute_reply": "2025-12-06T08:33:26.707932Z"
    },
    "papermill": {
     "duration": 0.031702,
     "end_time": "2025-12-06T08:33:26.710466",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.678764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HR images: 800\n",
      "Example files: ['0566.png', '0115.png', '0050.png', '0501.png', '0263.png', '0133.png', '0563.png', '0693.png', '0006.png', '0516.png']\n"
     ]
    }
   ],
   "source": [
    "# Correct DIV2K HR directory (your screenshot confirmed this path)\n",
    "HR_DIR = \"/kaggle/input/div2k-dataset/DIV2K_train_HR/DIV2K_train_HR\"\n",
    "\n",
    "# Show some images to confirm\n",
    "print(\"Total HR images:\", len(os.listdir(HR_DIR)))\n",
    "print(\"Example files:\", os.listdir(HR_DIR)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55cabd",
   "metadata": {
    "papermill": {
     "duration": 0.001964,
     "end_time": "2025-12-06T08:33:26.715024",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.713060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **3) Dataset class (on-the-fly JPEG compress & patch extraction)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8662d8ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T08:33:26.721402Z",
     "iopub.status.busy": "2025-12-06T08:33:26.720081Z",
     "iopub.status.idle": "2025-12-06T08:33:26.733838Z",
     "shell.execute_reply": "2025-12-06T08:33:26.732795Z"
    },
    "papermill": {
     "duration": 0.018671,
     "end_time": "2025-12-06T08:33:26.735631",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.716960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DIV2KJPEGDataset(Dataset):\n",
    "    def __init__(self, hr_dir, quality=10, patch_size=80, stride=79, augment=True, max_patches_per_image=40):\n",
    "        self.hr_paths = sorted([\n",
    "            os.path.join(hr_dir, f) for f in os.listdir(hr_dir)\n",
    "            if f.lower().endswith(('.png','.jpg','.jpeg'))\n",
    "        ])\n",
    "        \n",
    "        self.quality = quality\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.augment = augment\n",
    "        self.max_patches_per_image = max_patches_per_image\n",
    "        \n",
    "        self.index = []\n",
    "        for i, p in enumerate(self.hr_paths):\n",
    "            img = Image.open(p)\n",
    "            w, h = img.size\n",
    "            coords = []\n",
    "            for x in range(0, max(1, w - patch_size), stride):\n",
    "                for y in range(0, max(1, h - patch_size), stride):\n",
    "                    coords.append((x, y))\n",
    "            if len(coords) > max_patches_per_image:\n",
    "                coords = random.sample(coords, max_patches_per_image)\n",
    "            for (x, y) in coords:\n",
    "                self.index.append((i, x, y))\n",
    "        \n",
    "        print(f\"Dataset created: images={len(self.hr_paths)} patches={len(self.index)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx, x, y = self.index[idx]\n",
    "        path = self.hr_paths[img_idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "\n",
    "        patch = img.crop((x, y, x+self.patch_size, y+self.patch_size))\n",
    "\n",
    "        # JPEG compression\n",
    "        from io import BytesIO\n",
    "        buf = BytesIO()\n",
    "        patch.save(buf, format='JPEG', quality=self.quality)\n",
    "        buf.seek(0)\n",
    "        jpeg_patch = Image.open(buf).convert('RGB')\n",
    "\n",
    "        t_gt = TF.to_tensor(patch)\n",
    "        t_jpeg = TF.to_tensor(jpeg_patch)\n",
    "\n",
    "        if self.augment:\n",
    "            if random.random()<0.5:\n",
    "                t_gt = TF.hflip(t_gt); t_jpeg = TF.hflip(t_jpeg)\n",
    "            if random.random()<0.5:\n",
    "                t_gt = TF.vflip(t_gt); t_jpeg = TF.vflip(t_jpeg)\n",
    "\n",
    "        return t_jpeg, t_gt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4aec1",
   "metadata": {
    "papermill": {
     "duration": 0.001989,
     "end_time": "2025-12-06T08:33:26.740245",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.738256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **4) LEJR Compact model (PyTorch)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714c9ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T08:33:26.745595Z",
     "iopub.status.busy": "2025-12-06T08:33:26.745173Z",
     "iopub.status.idle": "2025-12-06T08:33:26.753401Z",
     "shell.execute_reply": "2025-12-06T08:33:26.751800Z"
    },
    "papermill": {
     "duration": 0.012648,
     "end_time": "2025-12-06T08:33:26.754817",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.742169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def depthwise_conv(in_channels):\n",
    "    return nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, groups=in_channels)\n",
    "\n",
    "class LocalExcitationBlock(nn.Module):\n",
    "    def __init__(self, ch=64):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.dw = depthwise_conv(ch)\n",
    "        self.pw = nn.Conv2d(ch, ch, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.prelu(self.conv(x))\n",
    "        w = self.sigmoid(self.pw(self.dw(res)))\n",
    "        return res * w\n",
    "\n",
    "class LEJR_Compact(nn.Module):\n",
    "    def __init__(self, blocks=10, ch=64):\n",
    "        super().__init__()\n",
    "        self.entry = nn.Conv2d(3, ch, 3, padding=1)\n",
    "        self.blocks = nn.ModuleList([LocalExcitationBlock(ch) for _ in range(blocks)])\n",
    "        self.exit = nn.Conv2d(ch, 3, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.entry(x)\n",
    "        for b in self.blocks:\n",
    "            out = b(out)\n",
    "        return self.exit(out) + x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0a028",
   "metadata": {
    "papermill": {
     "duration": 0.00207,
     "end_time": "2025-12-06T08:33:26.759331",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.757261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **5) Training loop (L1 then fine-tune L2). Small run configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5213e9e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T08:33:26.764766Z",
     "iopub.status.busy": "2025-12-06T08:33:26.764484Z",
     "iopub.status.idle": "2025-12-06T08:33:34.155247Z",
     "shell.execute_reply": "2025-12-06T08:33:34.153794Z"
    },
    "papermill": {
     "duration": 7.395774,
     "end_time": "2025-12-06T08:33:34.157197",
     "exception": false,
     "start_time": "2025-12-06T08:33:26.761423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created: images=800 patches=32000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DIV2KJPEGDataset(\n",
    "    HR_DIR,\n",
    "    quality=10,\n",
    "    patch_size=80,\n",
    "    stride=79,\n",
    "    augment=True,\n",
    "    max_patches_per_image=40\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf13ff8",
   "metadata": {
    "papermill": {
     "duration": 0.002526,
     "end_time": "2025-12-06T08:33:34.162989",
     "exception": false,
     "start_time": "2025-12-06T08:33:34.160463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **6) Test on LIVE1 and compute PSNR / save outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdcef2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T08:33:34.169147Z",
     "iopub.status.busy": "2025-12-06T08:33:34.168757Z",
     "iopub.status.idle": "2025-12-06T16:26:56.027948Z",
     "shell.execute_reply": "2025-12-06T16:26:56.026506Z"
    },
    "papermill": {
     "duration": 28402.024381,
     "end_time": "2025-12-06T16:26:56.189571",
     "exception": false,
     "start_time": "2025-12-06T08:33:34.165190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:35:39<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Loss: 0.035630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:34:00<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Loss: 0.035547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:35:00<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Loss: 0.030322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:34:40<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Loss: 0.025135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:34:01<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Loss: 0.030391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LEJR_Compact().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "epochs = 5  # increase to 40–100 for full training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for jpeg, gt in tqdm(train_loader):\n",
    "        jpeg = jpeg.to(device)\n",
    "        gt = gt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(jpeg)\n",
    "        loss = criterion(out, gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3debb",
   "metadata": {
    "papermill": {
     "duration": 0.509287,
     "end_time": "2025-12-06T16:26:57.068664",
     "exception": false,
     "start_time": "2025-12-06T16:26:56.559377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**7) Tips & Next steps**\n",
    "\n",
    "If dataset paths differ, update detection in cell 1 and variables HR_DIR / TEST_DIR.\n",
    "\n",
    "For full reproduction (paper):\n",
    "\n",
    "Train longer (paper: many iterations; here we used a small number for demo).\n",
    "\n",
    "Use full DIV2K (800 imgs), larger max_patches_per_image, more epochs.\n",
    "\n",
    "Use the baseline LEJR (with down/up scaling & recursion depth) instead of compact for SOTA.\n",
    "\n",
    "To use GAN (LEJR_GAN): add a discriminator model, VGG perceptual loss, alternate training. Ask me and I'll add the GAN cells.\n",
    "\n",
    "To download outputs from Kaggle: go to Output panel or click the files in the left sidebar (/kaggle/working/restored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5a0def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T16:26:57.800980Z",
     "iopub.status.busy": "2025-12-06T16:26:57.800606Z",
     "iopub.status.idle": "2025-12-06T16:26:57.817749Z",
     "shell.execute_reply": "2025-12-06T16:26:57.816579Z"
    },
    "papermill": {
     "duration": 0.378739,
     "end_time": "2025-12-06T16:26:57.819053",
     "exception": false,
     "start_time": "2025-12-06T16:26:57.440314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"/kaggle/working/lejr_compact.pth\")\n",
    "print(\"Model saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 286056,
     "sourceId": 588358,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1757438,
     "sourceId": 2869701,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28430.744079,
   "end_time": "2025-12-06T16:27:01.594650",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-06T08:33:10.850571",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
