{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx6kzNDYB0W3dZEITAkN+S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 1. THE ENET ARCHITECTURE (CORRECTED)\n",
        "# ==========================================\n",
        "\n",
        "class InitialBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    The initial block of ENet.\n",
        "    Concatenates a 3x3 conv (stride 2) and a max pooling layer.\n",
        "    Input: 3 channels -> Output: 13 (conv) + 3 (pool) = 16 channels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=13):\n",
        "        super(InitialBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels + in_channels)\n",
        "        self.pool = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.conv(x)\n",
        "        pool = self.pool(x)\n",
        "        out = torch.cat([conv, pool], dim=1)  # Concatenate -> 16 channels\n",
        "        out = self.batch_norm(out)\n",
        "        out = self.prelu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    \"\"\"\n",
        "    The main building block of ENet.\n",
        "    Handles Downsampling (Concat) and Regular (Add) connections differently.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, internal_ratio=4, kernel_size=3, padding=1, dilation=1,\n",
        "                 asymmetric=False, dropout_prob=0.1, downsample=False, upsample=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.upsample = upsample\n",
        "        self.main_branch_pool_indices = None\n",
        "\n",
        "        # Calculate internal channels\n",
        "        internal_channels = in_channels // internal_ratio\n",
        "\n",
        "        # KEY FIX: In downsampling, extension branch must output the *difference* in channels\n",
        "        # so that Concat(Main(16), Ext(48)) == 64\n",
        "        if downsample:\n",
        "            self.ext_channels = out_channels - in_channels\n",
        "        else:\n",
        "            self.ext_channels = out_channels\n",
        "\n",
        "        # --- Main Branch ---\n",
        "        if downsample:\n",
        "            self.main_pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
        "        elif upsample:\n",
        "            self.main_unpool = nn.MaxUnpool2d(kernel_size=2)\n",
        "            self.main_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "            self.main_bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # --- Extension Branch ---\n",
        "        # 1. Projection (1x1 or 2x2)\n",
        "        if downsample:\n",
        "            self.ext_conv1 = nn.Conv2d(in_channels, internal_channels, kernel_size=2, stride=2, bias=False)\n",
        "        else:\n",
        "            self.ext_conv1 = nn.Conv2d(in_channels, internal_channels, kernel_size=1, bias=False)\n",
        "        self.ext_bn1 = nn.BatchNorm2d(internal_channels)\n",
        "        self.ext_prelu1 = nn.PReLU()\n",
        "\n",
        "        # 2. Main Conv (Regular, Dilated, or Asymmetric)\n",
        "        if asymmetric:\n",
        "            self.ext_conv2 = nn.Sequential(\n",
        "                nn.Conv2d(internal_channels, internal_channels, kernel_size=(kernel_size, 1), padding=(padding, 0),\n",
        "                          dilation=dilation, bias=False),\n",
        "                nn.BatchNorm2d(internal_channels),\n",
        "                nn.PReLU(),\n",
        "                nn.Conv2d(internal_channels, internal_channels, kernel_size=(1, kernel_size), padding=(0, padding),\n",
        "                          dilation=dilation, bias=False),\n",
        "                nn.BatchNorm2d(internal_channels),\n",
        "                nn.PReLU()\n",
        "            )\n",
        "        elif upsample:\n",
        "            self.ext_conv2 = nn.ConvTranspose2d(internal_channels, internal_channels, kernel_size=kernel_size,\n",
        "                                                padding=padding, output_padding=1, stride=2, bias=False)\n",
        "            self.ext_bn2 = nn.BatchNorm2d(internal_channels)\n",
        "            self.ext_prelu2 = nn.PReLU()\n",
        "        else:\n",
        "            self.ext_conv2 = nn.Conv2d(internal_channels, internal_channels, kernel_size=kernel_size, padding=padding,\n",
        "                                       dilation=dilation, bias=False)\n",
        "            self.ext_bn2 = nn.BatchNorm2d(internal_channels)\n",
        "            self.ext_prelu2 = nn.PReLU()\n",
        "\n",
        "        # 3. Expansion (1x1)\n",
        "        # Note: We use self.ext_channels calculated above\n",
        "        self.ext_conv3 = nn.Conv2d(internal_channels, self.ext_channels, kernel_size=1, bias=False)\n",
        "        self.ext_bn3 = nn.BatchNorm2d(self.ext_channels)\n",
        "        self.ext_prelu3 = nn.PReLU()\n",
        "        self.ext_dropout = nn.Dropout2d(p=dropout_prob)\n",
        "\n",
        "        self.final_prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x, max_indices=None):\n",
        "        # Main Branch\n",
        "        main = x\n",
        "        if self.downsample:\n",
        "            main, self.main_branch_pool_indices = self.main_pool(main)\n",
        "        elif self.upsample:\n",
        "            # FIX: Conv (reduce channels) -> BN -> Unpool (match indices channels)\n",
        "            main = self.main_conv(main)\n",
        "            main = self.main_bn(main)\n",
        "            main = self.main_unpool(main, max_indices)\n",
        "\n",
        "        # Extension Branch\n",
        "        ext = self.ext_conv1(x)\n",
        "        ext = self.ext_bn1(ext)\n",
        "        ext = self.ext_prelu1(ext)\n",
        "\n",
        "        if hasattr(self, 'ext_conv2'):\n",
        "            ext = self.ext_conv2(ext)\n",
        "            if self.upsample and hasattr(self, 'ext_bn2'):\n",
        "                ext = self.ext_bn2(ext)\n",
        "                ext = self.ext_prelu2(ext)\n",
        "\n",
        "        ext = self.ext_conv3(ext)\n",
        "        ext = self.ext_bn3(ext)\n",
        "        ext = self.ext_prelu3(ext)\n",
        "        ext = self.ext_dropout(ext)\n",
        "\n",
        "        # Combine\n",
        "        if self.downsample:\n",
        "            # Concatenate main and ext for downsampling\n",
        "            out = torch.cat((main, ext), 1)\n",
        "        else:\n",
        "            # Add for regular residual blocks\n",
        "            out = main + ext\n",
        "\n",
        "        return self.final_prelu(out)\n",
        "\n",
        "\n",
        "class ENet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ENet, self).__init__()\n",
        "\n",
        "        # Initial: 3 -> 16\n",
        "        self.initial = InitialBlock(in_channels=3, out_channels=13)\n",
        "\n",
        "        # Stage 1: 16 -> 64\n",
        "        self.bottleneck1_0 = Bottleneck(16, 64, downsample=True, dropout_prob=0.01)  # Downsample\n",
        "        self.bottleneck1_1 = Bottleneck(64, 64, dropout_prob=0.01)  # Regular\n",
        "        self.bottleneck1_2 = Bottleneck(64, 64, dropout_prob=0.01)\n",
        "        self.bottleneck1_3 = Bottleneck(64, 64, dropout_prob=0.01)\n",
        "        self.bottleneck1_4 = Bottleneck(64, 64, dropout_prob=0.01)\n",
        "\n",
        "        # Stage 2: 64 -> 128\n",
        "        self.bottleneck2_0 = Bottleneck(64, 128, downsample=True)\n",
        "        self.bottleneck2_1 = Bottleneck(128, 128)\n",
        "        self.bottleneck2_2 = Bottleneck(128, 128, dilation=2, padding=2)\n",
        "        self.bottleneck2_3 = Bottleneck(128, 128, asymmetric=True, kernel_size=5, padding=2)\n",
        "        self.bottleneck2_4 = Bottleneck(128, 128, dilation=4, padding=4)\n",
        "\n",
        "        # Stage 3 (Usually repeats Stage 2) - Simplified here for brevity\n",
        "        self.bottleneck3_1 = Bottleneck(128, 128)\n",
        "        self.bottleneck3_2 = Bottleneck(128, 128, dilation=2, padding=2)\n",
        "        self.bottleneck3_3 = Bottleneck(128, 128, asymmetric=True, kernel_size=5, padding=2)\n",
        "\n",
        "        # Stage 4 (Decoder): 128 -> 64\n",
        "        self.bottleneck4_0 = Bottleneck(128, 64, upsample=True)\n",
        "        self.bottleneck4_1 = Bottleneck(64, 64)\n",
        "        self.bottleneck4_2 = Bottleneck(64, 64)\n",
        "\n",
        "        # Stage 5 (Decoder): 64 -> 16\n",
        "        self.bottleneck5_0 = Bottleneck(64, 16, upsample=True)\n",
        "        self.bottleneck5_1 = Bottleneck(16, 16)\n",
        "\n",
        "        # Fullconv: 16 -> num_classes\n",
        "        self.fullconv = nn.ConvTranspose2d(16, num_classes, kernel_size=2, stride=2, padding=0, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial\n",
        "        x = self.initial(x)  # 16\n",
        "\n",
        "        # Stage 1\n",
        "        x = self.bottleneck1_0(x)  # 64\n",
        "        indices1 = self.bottleneck1_0.main_branch_pool_indices\n",
        "        x = self.bottleneck1_1(x)\n",
        "        x = self.bottleneck1_2(x)\n",
        "        x = self.bottleneck1_3(x)\n",
        "        x = self.bottleneck1_4(x)\n",
        "\n",
        "        # Stage 2\n",
        "        x = self.bottleneck2_0(x)  # 128\n",
        "        indices2 = self.bottleneck2_0.main_branch_pool_indices\n",
        "        x = self.bottleneck2_1(x)\n",
        "        x = self.bottleneck2_2(x)\n",
        "        x = self.bottleneck2_3(x)\n",
        "        x = self.bottleneck2_4(x)\n",
        "\n",
        "        # Stage 3\n",
        "        x = self.bottleneck3_1(x)\n",
        "        x = self.bottleneck3_2(x)\n",
        "        x = self.bottleneck3_3(x)\n",
        "\n",
        "        # Stage 4\n",
        "        x = self.bottleneck4_0(x, indices2)  # 64\n",
        "        x = self.bottleneck4_1(x)\n",
        "        x = self.bottleneck4_2(x)\n",
        "\n",
        "        # Stage 5\n",
        "        x = self.bottleneck5_0(x, indices1)  # 16\n",
        "        x = self.bottleneck5_1(x)\n",
        "\n",
        "        # Output\n",
        "        x = self.fullconv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pckXSjEP2T4P"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "model = ENet(num_classes=2)\n",
        "model.load_state_dict(torch.load(\"enet_best.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model Loaded Successfully!\")\n",
        "\n",
        "video_path = \"test_video.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Video output writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(\"test_output_video.mp4\", fourcc, 30, (1280, 720))\n",
        "\n",
        "def preprocess(frame):\n",
        "    img = cv2.resize(frame, (512, 256))\n",
        "    img = img / 255.0\n",
        "    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
        "    img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
        "    return img.to(device)\n",
        "\n",
        "def predict_mask(input_tensor):\n",
        "    with torch.no_grad():\n",
        "        pred = model(input_tensor)\n",
        "        pred = F.softmax(pred, dim=1)[:, 1]\n",
        "        mask = (pred > 0.5).float()[0].cpu().numpy()\n",
        "    return mask\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    original_frame = frame.copy()\n",
        "    original_frame = cv2.resize(original_frame, (1280, 720))\n",
        "\n",
        "    prep = preprocess(frame)\n",
        "    mask = predict_mask(prep)\n",
        "\n",
        "    mask_resized = cv2.resize(mask, (1280, 720))\n",
        "\n",
        "    overlay = original_frame.copy()\n",
        "    overlay[mask_resized > 0.5] = [57, 255, 20]\n",
        "\n",
        "    result = cv2.addWeighted(original_frame, 0.7, overlay, 0.3, 0)\n",
        "\n",
        "\n",
        "    out.write(result)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Video saved as output_lane_video.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fv4FgyWy2mrB",
        "outputId": "4d7b1b78-c7a5-4af0-967e-2ee25538ee0b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'enet_best.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3226382549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enet_best.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'enet_best.pth'"
          ]
        }
      ]
    }
  ]
}